{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import DataCollatorForLanguageModeling, AutoModelForCausalLM, TrainingArguments, Trainer, \\\n",
    "    AutoTokenizer, GPT2LMHeadModel, GPT2Config, GPT2Tokenizer, OpenAIGPTLMHeadModel, OpenAIGPTConfig, \\\n",
    "    AutoModelForSequenceClassification, pipeline\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from sklearn.metrics import classification_report\n",
    "import math\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T02:04:40.735766081Z",
     "start_time": "2024-02-20T02:04:40.723844225Z"
    }
   },
   "id": "60ba6422d1485aab"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA A100 80GB PCIe\n"
     ]
    }
   ],
   "source": [
    "# Set to GPU if available.\n",
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('Using GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('No GPU available, using CPU instead.')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T00:51:10.368278397Z",
     "start_time": "2024-02-20T00:51:10.350549407Z"
    }
   },
   "id": "6f4e6607613eaf22"
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dkrogh/venv/lib/python3.10/site-packages/datasets/load.py:2516: FutureWarning: 'ignore_verifications' was deprecated in favor of 'verification_mode' in version 2.9.1 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'verification_mode=no_checks' instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading readme:   0%|          | 0.00/10.5k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "21f187e84a6d4199a3490f26466c244e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading data:   0%|          | 0.00/733k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fcf4ce9f220744819de5040a4619155f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading data:   0%|          | 0.00/6.36M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8c22319613054bc6969d23406f4fb0b4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading data:   0%|          | 0.00/657k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "10fd9694ff7c4344818cc2279124c97c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating test split:   0%|          | 0/4358 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8aaa367744e24b5e8c79c1f5d9f714cf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating train split:   0%|          | 0/36718 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "69ac6871f10f44f293dd9a312d5d5061"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating validation split:   0%|          | 0/3760 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b87472266eae4e17bb5e4823b636d87d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"wikitext\", 'wikitext-2-raw-v1', download_mode=\"force_redownload\", ignore_verifications=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T02:06:31.316885444Z",
     "start_time": "2024-02-20T02:06:24.805076899Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n",
      "Using eos_token, but it is not set yet.\n"
     ]
    }
   ],
   "source": [
    "#tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer = AutoTokenizer.from_pretrained('openai-gpt')\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "if tokenizer.eos_token is None:\n",
    "    tokenizer.add_special_tokens({'eos_token': '[EOS]'})\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T02:06:37.188781710Z",
     "start_time": "2024-02-20T02:06:37.014633444Z"
    }
   },
   "id": "8078863341bd6d23"
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40478\n"
     ]
    }
   ],
   "source": [
    "#print(dataset[\"train\"][3])\n",
    "print(tokenizer.vocab_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T02:06:37.752294386Z",
     "start_time": "2024-02-20T02:06:37.738450181Z"
    }
   },
   "id": "ec18aaf7f5f2851d"
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "def preproc_data(data):\n",
    "    return tokenizer([s for s in data[\"text\"]])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T02:06:38.224180080Z",
     "start_time": "2024-02-20T02:06:38.210031613Z"
    }
   },
   "id": "fdc87b56b1d34be2"
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/4358 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "542d9eb7610a4b01a3ca8e0fd22301de"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (535 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/36718 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "463572490b28434cb862a38a1e7484e8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/3760 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "604fc591cd3e464a83f1e2e5ab14953f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(preproc_data, batched=True, remove_columns=dataset[\"train\"].column_names)\n",
    "# tokenized_dataset = tokenized_dataset.remove_columns('text')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T02:06:41.833230281Z",
     "start_time": "2024-02-20T02:06:39.301162890Z"
    }
   },
   "id": "325a4106926e5763"
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [303, 2007, 3680, 8593, 32543, 17887, 303], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_dataset['train'][1])\n",
    "#tokenizer([' = Valkyria Chronicles III = \\n'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T02:06:41.833966075Z",
     "start_time": "2024-02-20T02:06:41.821309457Z"
    }
   },
   "id": "366ea4186bd45faa"
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/4358 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f9f56bd2acb14d4898285b878d413444"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/36718 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e4523e6994ab422a8e1b5fc0d292b465"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/3760 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "90914501003c445b8db621aeeb181dc3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "block_size = 128\n",
    "\n",
    "def group_texts(examples):\n",
    "    # This partially copied from hugging face causal modeling tutorial.\n",
    "    # Concatenate all the tokens in a batch\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    \n",
    "    # Cut off any extra that won't be divisible by block size\n",
    "    if total_length >= block_size:\n",
    "        total_length = (total_length // block_size) * block_size\n",
    "    \n",
    "    # Split by chunks of block_size.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    #result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "\n",
    "grouped_dataset = tokenized_dataset.map(group_texts, batched=True)\n",
    "#print(concat)\n",
    "#tokenized_dataset.map(test_f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T02:06:47.656492800Z",
     "start_time": "2024-02-20T02:06:41.962933719Z"
    }
   },
   "id": "3bac754f5ceaf219"
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [481, 244, 18220, 244, 240, 246, 1922, 679, 4381, 6611, 6255, 481, 7037, 498, 2857, 6149, 2167, 481, 1420, 10291, 6847, 2557, 763, 9036, 2752, 1301, 10940, 488, 640, 29185, 1006, 481, 12514, 6611, 244, 926, 14231, 253, 6996, 244, 239, 481, 2467, 1351, 10051, 500, 27812, 240, 3807, 715, 246, 1719, 8487, 498, 481, 1129, 1256, 504, 2007, 3680, 8593, 32543, 7735, 239, 1000, 507, 19914, 481, 7789, 4374, 498, 481, 5025, 240, 507, 1359, 1079, 1040, 9163, 25112, 240, 1389, 557, 1457, 481, 2467, 725, 14741, 562, 5025, 24019, 239, 6371, 11723, 565, 6017, 1642, 832, 254, 488, 35526, 1617, 490, 571, 8944, 540, 951, 31990, 1109, 2118, 617, 5144, 23688, 240, 1412, 556, 2007, 3680, 8593, 32543, 7735, 6760, 14152, 8944, 21821, 30937, 239, 246], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "print(grouped_dataset['train'][1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T02:06:47.656957368Z",
     "start_time": "2024-02-20T02:06:47.637254281Z"
    }
   },
   "id": "43da4f698d001fd"
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T02:06:47.657065067Z",
     "start_time": "2024-02-20T02:06:47.637477622Z"
    }
   },
   "id": "f55b3899f8c664ca"
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "N_HEAD = 4\n",
    "N_DIM = 128\n",
    "N_LAYER = 4\n",
    "VOCAB_SIZE = tokenizer.vocab_size\n",
    "\n",
    "configuration = OpenAIGPTConfig(n_head=N_HEAD, n_embd=N_DIM, n_layer=N_LAYER, vocab_size=VOCAB_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T02:06:47.657157042Z",
     "start_time": "2024-02-20T02:06:47.637608359Z"
    }
   },
   "id": "dbf7b0331086ea95"
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "model = OpenAIGPTLMHeadModel(configuration)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T02:06:47.657244367Z",
     "start_time": "2024-02-20T02:06:47.637755618Z"
    }
   },
   "id": "678cc8f6bfa79a1"
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAIGPTConfig {\n",
      "  \"afn\": \"gelu\",\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"openai-gpt\",\n",
      "  \"n_embd\": 32,\n",
      "  \"n_head\": 2,\n",
      "  \"n_layer\": 2,\n",
      "  \"n_positions\": 512,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.32.1\",\n",
      "  \"vocab_size\": 40478\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(configuration)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T02:06:47.920693042Z",
     "start_time": "2024-02-20T02:06:47.709401837Z"
    }
   },
   "id": "6ce8a199cb46935d"
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "metric = evaluate.load('accuracy')\n",
    "def compute_metrics(model_out):\n",
    "    # Also from huggingface tutorial (not used)\n",
    "    logits, labels = model_out\n",
    "    print(logits)\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T02:07:12.572393683Z",
     "start_time": "2024-02-20T02:07:12.079505024Z"
    }
   },
   "id": "180524fbdd0c5685"
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "model_dir = 'trained_hw2_model'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T02:07:15.765697171Z",
     "start_time": "2024-02-20T02:07:15.725791106Z"
    }
   },
   "id": "983e515523217524"
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found safetensors installation, but --save_safetensors=False. Safetensors should be a preferred weights saving format due to security and performance reasons. If your model cannot be saved by safetensors please feel free to open an issue at https://github.com/huggingface/safetensors!\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='trained_hw2_model',\n",
    "    evaluation_strategy='epoch',\n",
    "    disable_tqdm=False,\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=50,\n",
    "    log_level='info',\n",
    "    logging_strategy='epoch',\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=64)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T02:51:28.909039207Z",
     "start_time": "2024-02-20T02:51:28.867219311Z"
    }
   },
   "id": "1979fa278e2c2680"
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=grouped_dataset['train'],\n",
    "    eval_dataset=grouped_dataset['validation'],\n",
    "    #compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T02:51:29.161250619Z",
     "start_time": "2024-02-20T02:51:29.144735284Z"
    }
   },
   "id": "d06487168957da43"
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "#print(h for h in trainer.state.log_history[2])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T02:51:30.256835755Z",
     "start_time": "2024-02-20T02:51:30.251514322Z"
    }
   },
   "id": "8db6d47cc37bcae3"
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 18,391\n",
      "  Num Epochs = 50\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14,400\n",
      "  Number of trainable parameters = 1,337,088\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='14400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [    2/14400 : < :, Epoch 0.00/50]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1912\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to trained_hw2_model/checkpoint-500\n",
      "Configuration saved in trained_hw2_model/checkpoint-500/config.json\n",
      "Configuration saved in trained_hw2_model/checkpoint-500/generation_config.json\n",
      "Model weights saved in trained_hw2_model/checkpoint-500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1912\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1912\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to trained_hw2_model/checkpoint-1000\n",
      "Configuration saved in trained_hw2_model/checkpoint-1000/config.json\n",
      "Configuration saved in trained_hw2_model/checkpoint-1000/generation_config.json\n",
      "Model weights saved in trained_hw2_model/checkpoint-1000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1912\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1912\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to trained_hw2_model/checkpoint-1500\n",
      "Configuration saved in trained_hw2_model/checkpoint-1500/config.json\n",
      "Configuration saved in trained_hw2_model/checkpoint-1500/generation_config.json\n",
      "Model weights saved in trained_hw2_model/checkpoint-1500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1912\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to trained_hw2_model/checkpoint-2000\n",
      "Configuration saved in trained_hw2_model/checkpoint-2000/config.json\n",
      "Configuration saved in trained_hw2_model/checkpoint-2000/generation_config.json\n",
      "Model weights saved in trained_hw2_model/checkpoint-2000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1912\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1912\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to trained_hw2_model/checkpoint-2500\n",
      "Configuration saved in trained_hw2_model/checkpoint-2500/config.json\n",
      "Configuration saved in trained_hw2_model/checkpoint-2500/generation_config.json\n",
      "Model weights saved in trained_hw2_model/checkpoint-2500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1912\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1912\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to trained_hw2_model/checkpoint-3000\n",
      "Configuration saved in trained_hw2_model/checkpoint-3000/config.json\n",
      "Configuration saved in trained_hw2_model/checkpoint-3000/generation_config.json\n",
      "Model weights saved in trained_hw2_model/checkpoint-3000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1912\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1912\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to trained_hw2_model/checkpoint-3500\n",
      "Configuration saved in trained_hw2_model/checkpoint-3500/config.json\n",
      "Configuration saved in trained_hw2_model/checkpoint-3500/generation_config.json\n",
      "Model weights saved in trained_hw2_model/checkpoint-3500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1912\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to trained_hw2_model/checkpoint-4000\n",
      "Configuration saved in trained_hw2_model/checkpoint-4000/config.json\n",
      "Configuration saved in trained_hw2_model/checkpoint-4000/generation_config.json\n",
      "Model weights saved in trained_hw2_model/checkpoint-4000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1912\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1912\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to trained_hw2_model/checkpoint-4500\n",
      "Configuration saved in trained_hw2_model/checkpoint-4500/config.json\n",
      "Configuration saved in trained_hw2_model/checkpoint-4500/generation_config.json\n",
      "Model weights saved in trained_hw2_model/checkpoint-4500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1912\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1912\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to trained_hw2_model/checkpoint-5000\n",
      "Configuration saved in trained_hw2_model/checkpoint-5000/config.json\n",
      "Configuration saved in trained_hw2_model/checkpoint-5000/generation_config.json\n",
      "Model weights saved in trained_hw2_model/checkpoint-5000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1912\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1912\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to trained_hw2_model/checkpoint-5500\n",
      "Configuration saved in trained_hw2_model/checkpoint-5500/config.json\n",
      "Configuration saved in trained_hw2_model/checkpoint-5500/generation_config.json\n",
      "Model weights saved in trained_hw2_model/checkpoint-5500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1912\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to trained_hw2_model/checkpoint-6000\n",
      "Configuration saved in trained_hw2_model/checkpoint-6000/config.json\n",
      "Configuration saved in trained_hw2_model/checkpoint-6000/generation_config.json\n",
      "Model weights saved in trained_hw2_model/checkpoint-6000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1912\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1912\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to trained_hw2_model/checkpoint-6500\n",
      "Configuration saved in trained_hw2_model/checkpoint-6500/config.json\n",
      "Configuration saved in trained_hw2_model/checkpoint-6500/generation_config.json\n",
      "Model weights saved in trained_hw2_model/checkpoint-6500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1912\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1912\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to trained_hw2_model/checkpoint-7000\n",
      "Configuration saved in trained_hw2_model/checkpoint-7000/config.json\n",
      "Configuration saved in trained_hw2_model/checkpoint-7000/generation_config.json\n",
      "Model weights saved in trained_hw2_model/checkpoint-7000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1912\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1912\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to trained_hw2_model/checkpoint-7500\n",
      "Configuration saved in trained_hw2_model/checkpoint-7500/config.json\n",
      "Configuration saved in trained_hw2_model/checkpoint-7500/generation_config.json\n",
      "Model weights saved in trained_hw2_model/checkpoint-7500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1912\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to trained_hw2_model/checkpoint-8000\n",
      "Configuration saved in trained_hw2_model/checkpoint-8000/config.json\n",
      "Configuration saved in trained_hw2_model/checkpoint-8000/generation_config.json\n",
      "Model weights saved in trained_hw2_model/checkpoint-8000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1912\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1912\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to trained_hw2_model/checkpoint-8500\n",
      "Configuration saved in trained_hw2_model/checkpoint-8500/config.json\n",
      "Configuration saved in trained_hw2_model/checkpoint-8500/generation_config.json\n",
      "Model weights saved in trained_hw2_model/checkpoint-8500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1912\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1912\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to trained_hw2_model/checkpoint-9000\n",
      "Configuration saved in trained_hw2_model/checkpoint-9000/config.json\n",
      "Configuration saved in trained_hw2_model/checkpoint-9000/generation_config.json\n",
      "Model weights saved in trained_hw2_model/checkpoint-9000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1912\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to trained_hw2_model/checkpoint-9500\n",
      "Configuration saved in trained_hw2_model/checkpoint-9500/config.json\n",
      "Configuration saved in trained_hw2_model/checkpoint-9500/generation_config.json\n",
      "Model weights saved in trained_hw2_model/checkpoint-9500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1912\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1912\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to trained_hw2_model/checkpoint-10000\n",
      "Configuration saved in trained_hw2_model/checkpoint-10000/config.json\n",
      "Configuration saved in trained_hw2_model/checkpoint-10000/generation_config.json\n",
      "Model weights saved in trained_hw2_model/checkpoint-10000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1912\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1912\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to trained_hw2_model/checkpoint-10500\n",
      "Configuration saved in trained_hw2_model/checkpoint-10500/config.json\n",
      "Configuration saved in trained_hw2_model/checkpoint-10500/generation_config.json\n",
      "Model weights saved in trained_hw2_model/checkpoint-10500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1912\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1912\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to trained_hw2_model/checkpoint-11000\n",
      "Configuration saved in trained_hw2_model/checkpoint-11000/config.json\n",
      "Configuration saved in trained_hw2_model/checkpoint-11000/generation_config.json\n",
      "Model weights saved in trained_hw2_model/checkpoint-11000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1912\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to trained_hw2_model/checkpoint-11500\n",
      "Configuration saved in trained_hw2_model/checkpoint-11500/config.json\n",
      "Configuration saved in trained_hw2_model/checkpoint-11500/generation_config.json\n",
      "Model weights saved in trained_hw2_model/checkpoint-11500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1912\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1912\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to trained_hw2_model/checkpoint-12000\n",
      "Configuration saved in trained_hw2_model/checkpoint-12000/config.json\n",
      "Configuration saved in trained_hw2_model/checkpoint-12000/generation_config.json\n",
      "Model weights saved in trained_hw2_model/checkpoint-12000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1912\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1912\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to trained_hw2_model/checkpoint-12500\n",
      "Configuration saved in trained_hw2_model/checkpoint-12500/config.json\n",
      "Configuration saved in trained_hw2_model/checkpoint-12500/generation_config.json\n",
      "Model weights saved in trained_hw2_model/checkpoint-12500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1912\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1912\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to trained_hw2_model/checkpoint-13000\n",
      "Configuration saved in trained_hw2_model/checkpoint-13000/config.json\n",
      "Configuration saved in trained_hw2_model/checkpoint-13000/generation_config.json\n",
      "Model weights saved in trained_hw2_model/checkpoint-13000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1912\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to trained_hw2_model/checkpoint-13500\n",
      "Configuration saved in trained_hw2_model/checkpoint-13500/config.json\n",
      "Configuration saved in trained_hw2_model/checkpoint-13500/generation_config.json\n",
      "Model weights saved in trained_hw2_model/checkpoint-13500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1912\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1912\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to trained_hw2_model/checkpoint-14000\n",
      "Configuration saved in trained_hw2_model/checkpoint-14000/config.json\n",
      "Configuration saved in trained_hw2_model/checkpoint-14000/generation_config.json\n",
      "Model weights saved in trained_hw2_model/checkpoint-14000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1912\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1912\n",
      "  Batch size = 64\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "TrainOutput(global_step=14400, training_loss=5.33978251139323, metrics={'train_runtime': 440.5097, 'train_samples_per_second': 2087.468, 'train_steps_per_second': 32.689, 'total_flos': 17943495475200.0, 'train_loss': 5.33978251139323, 'epoch': 50.0})"
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T02:58:51.873593192Z",
     "start_time": "2024-02-20T02:51:31.338779497Z"
    }
   },
   "id": "cb14b60143a7afe4"
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1912\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 319.66\n"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T02:59:50.346210215Z",
     "start_time": "2024-02-20T02:59:49.883210313Z"
    }
   },
   "id": "101ab744a6083574"
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in trained_hw2_model/config.json\n",
      "Configuration saved in trained_hw2_model/generation_config.json\n",
      "Model weights saved in trained_hw2_model/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "model_to_save = model.module if hasattr(model, 'module') else model\n",
    "model_to_save.save_pretrained(model_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T02:59:53.765570750Z",
     "start_time": "2024-02-20T02:59:53.757113170Z"
    }
   },
   "id": "df48e94d9ea333e6"
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [],
   "source": [
    "# Finetuning\n",
    "intent_train_path = \"./nlp244_hw2_data/hw2_train.csv\"\n",
    "intent_data = load_dataset(\"csv\", data_files=intent_train_path)['train']\n",
    "\n",
    "intent_data = intent_data.train_test_split(test_size=0.2)\n",
    "intent_train = intent_data['train'].flatten()\n",
    "intent_val = intent_data['test'].flatten()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T02:59:57.765971614Z",
     "start_time": "2024-02-20T02:59:57.441202165Z"
    }
   },
   "id": "ed940caa792109f8"
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [],
   "source": [
    "all_relations = list(sorted(set([j for d in intent_train[\"Core Relations\"] if d is not None for j in d.split()] + [\"None\"])))\n",
    "relation_to_idx = {r:i for i, r in enumerate(all_relations)}\n",
    "idx_to_relation = {i:r for i, r in enumerate(all_relations)}\n",
    "\n",
    "def preproc_intent_data(d):\n",
    "    # Tokenize\n",
    "    res = tokenizer(d['utterances'], max_length=50, padding='longest', truncation=True)\n",
    "    \n",
    "    # Encode core relations\n",
    "    if d[\"Core Relations\"] == None:\n",
    "        res['label'] = relation_to_idx[\"None\"]\n",
    "    else:\n",
    "        for r in d[\"Core Relations\"].split():\n",
    "            res[\"label\"] = relation_to_idx[r]\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T02:59:57.877389246Z",
     "start_time": "2024-02-20T02:59:57.854484234Z"
    }
   },
   "id": "ef02903ce4eeef79"
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/1802 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c9fe338bf9914f8fb85ddbebc46bb828"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/451 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5d0128f634ba475b8d52437ae5c8d9ec"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'label'],\n",
      "    num_rows: 1802\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "#intent_data = intent_data.map(preproc_intent_data, remove_columns=intent_train.column_names)\n",
    "intent_train_tok = intent_train.map(preproc_intent_data, remove_columns=intent_train.column_names)\n",
    "intent_val_tok = intent_val.map(preproc_intent_data, remove_columns=intent_val.column_names)\n",
    "print(intent_train_tok)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T03:00:00.051962877Z",
     "start_time": "2024-02-20T02:59:59.590789106Z"
    }
   },
   "id": "a326eba401b35993"
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[249, 823, 485, 1085, 6445, 702, 6760, 2703, 7738], [890, 562, 24997, 885, 522, 1785, 500, 8725], [626, 6097, 8395, 483, 5673, 775, 6445], [1572, 1085, 246, 4121, 500, 37088], [14121, 562, 27306], [640, 655, 775, 6445, 885, 500, 16237], [1085, 6445, 702, 23261], [1788, 510, 481, 11394, 498, 481, 4121, 2866, 15548], [1788, 4413, 20267, 17591], [1085, 589, 4132, 670, 3876, 11152, 260, 246, 783, 1777, 4121]]\n"
     ]
    }
   ],
   "source": [
    "print(intent_train_tok['input_ids'][0:10])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T03:00:01.014709908Z",
     "start_time": "2024-02-20T03:00:00.986115134Z"
    }
   },
   "id": "dda97c1df352806e"
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "ft_data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T03:00:03.574471548Z",
     "start_time": "2024-02-20T03:00:03.569542433Z"
    }
   },
   "id": "b30e8c247b836a6e"
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file trained_hw2_model/config.json\n",
      "Model config OpenAIGPTConfig {\n",
      "  \"_name_or_path\": \"trained_hw2_model\",\n",
      "  \"afn\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"OpenAIGPTLMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"None\",\n",
      "    \"1\": \"actor.gender\",\n",
      "    \"2\": \"gr.amount\",\n",
      "    \"3\": \"movie.country\",\n",
      "    \"4\": \"movie.directed_by\",\n",
      "    \"5\": \"movie.estimated_budget\",\n",
      "    \"6\": \"movie.genre\",\n",
      "    \"7\": \"movie.gross_revenue\",\n",
      "    \"8\": \"movie.initial_release_date\",\n",
      "    \"9\": \"movie.language\",\n",
      "    \"10\": \"movie.locations\",\n",
      "    \"11\": \"movie.music\",\n",
      "    \"12\": \"movie.produced_by\",\n",
      "    \"13\": \"movie.production_companies\",\n",
      "    \"14\": \"movie.rating\",\n",
      "    \"15\": \"movie.starring.actor\",\n",
      "    \"16\": \"movie.starring.character\",\n",
      "    \"17\": \"movie.subjects\",\n",
      "    \"18\": \"person.date_of_birth\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"None\": 0,\n",
      "    \"actor.gender\": 1,\n",
      "    \"gr.amount\": 2,\n",
      "    \"movie.country\": 3,\n",
      "    \"movie.directed_by\": 4,\n",
      "    \"movie.estimated_budget\": 5,\n",
      "    \"movie.genre\": 6,\n",
      "    \"movie.gross_revenue\": 7,\n",
      "    \"movie.initial_release_date\": 8,\n",
      "    \"movie.language\": 9,\n",
      "    \"movie.locations\": 10,\n",
      "    \"movie.music\": 11,\n",
      "    \"movie.produced_by\": 12,\n",
      "    \"movie.production_companies\": 13,\n",
      "    \"movie.rating\": 14,\n",
      "    \"movie.starring.actor\": 15,\n",
      "    \"movie.starring.character\": 16,\n",
      "    \"movie.subjects\": 17,\n",
      "    \"person.date_of_birth\": 18\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"openai-gpt\",\n",
      "  \"n_embd\": 32,\n",
      "  \"n_head\": 2,\n",
      "  \"n_layer\": 2,\n",
      "  \"n_positions\": 512,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.32.1\",\n",
      "  \"vocab_size\": 40478\n",
      "}\n",
      "\n",
      "loading weights file trained_hw2_model/pytorch_model.bin\n",
      "Some weights of the model checkpoint at trained_hw2_model were not used when initializing OpenAIGPTForSequenceClassification: ['lm_head.weight']\n",
      "- This IS expected if you are initializing OpenAIGPTForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing OpenAIGPTForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of OpenAIGPTForSequenceClassification were not initialized from the model checkpoint at trained_hw2_model and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 40480. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "data": {
      "text/plain": "OpenAIGPTForSequenceClassification(\n  (transformer): OpenAIGPTModel(\n    (tokens_embed): Embedding(40480, 32)\n    (positions_embed): Embedding(512, 32)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-1): 2 x Block(\n        (attn): Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n        (mlp): MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n  )\n  (score): Linear(in_features=32, out_features=19, bias=False)\n)"
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_model = AutoModelForSequenceClassification.from_pretrained(model_dir, num_labels=len(all_relations), id2label=idx_to_relation, label2id=relation_to_idx)\n",
    "ft_model.resize_token_embeddings(len(tokenizer))\n",
    "ft_model.config.pad_token_id = tokenizer.pad_token_id\n",
    "ft_model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T03:00:05.978069868Z",
     "start_time": "2024-02-20T03:00:05.901273627Z"
    }
   },
   "id": "58d58a07eaf8de51"
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found safetensors installation, but --save_safetensors=False. Safetensors should be a preferred weights saving format due to security and performance reasons. If your model cannot be saved by safetensors please feel free to open an issue at https://github.com/huggingface/safetensors!\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "ft_training_args = TrainingArguments(\n",
    "    output_dir='ft_trained_hw2_model',\n",
    "    evaluation_strategy='epoch',\n",
    "    disable_tqdm=False,\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    log_level='info'\n",
    ")\n",
    "\n",
    "ft_trainer = Trainer(\n",
    "    model=ft_model,\n",
    "    args=ft_training_args,\n",
    "    train_dataset=intent_train_tok,\n",
    "    eval_dataset=intent_val_tok,\n",
    "    data_collator=ft_data_collator,\n",
    "    #compute_metrics=compute_metrics\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T03:00:35.504012226Z",
     "start_time": "2024-02-20T03:00:35.454959375Z"
    }
   },
   "id": "73768acb4a343be0"
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 1,802\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1,130\n",
      "  Number of trainable parameters = 1,337,760\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='1130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   2/1130 : < :, Epoch 0.01/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 451\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 451\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 451\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 451\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ft_trained_hw2_model/checkpoint-500\n",
      "Configuration saved in ft_trained_hw2_model/checkpoint-500/config.json\n",
      "Model weights saved in ft_trained_hw2_model/checkpoint-500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 451\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 451\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 451\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 451\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ft_trained_hw2_model/checkpoint-1000\n",
      "Configuration saved in ft_trained_hw2_model/checkpoint-1000/config.json\n",
      "Model weights saved in ft_trained_hw2_model/checkpoint-1000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 451\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 451\n",
      "  Batch size = 16\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "TrainOutput(global_step=1130, training_loss=1.913348469691994, metrics={'train_runtime': 9.9398, 'train_samples_per_second': 1812.917, 'train_steps_per_second': 113.685, 'total_flos': 34773818112.0, 'train_loss': 1.913348469691994, 'epoch': 10.0})"
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T03:00:47.072868384Z",
     "start_time": "2024-02-20T03:00:37.121614139Z"
    }
   },
   "id": "bb2cd357534c3cda"
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to trained_hw2_model\n",
      "Configuration saved in trained_hw2_model/config.json\n",
      "Model weights saved in trained_hw2_model/pytorch_model.bin\n",
      "tokenizer config file saved in trained_hw2_model/tokenizer_config.json\n",
      "Special tokens file saved in trained_hw2_model/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": "('trained_hw2_model/tokenizer_config.json',\n 'trained_hw2_model/special_tokens_map.json',\n 'trained_hw2_model/vocab.json',\n 'trained_hw2_model/merges.txt',\n 'trained_hw2_model/added_tokens.json',\n 'trained_hw2_model/tokenizer.json')"
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_trainer.save_model(model_dir)\n",
    "tokenizer.save_pretrained(model_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T03:01:02.796226195Z",
     "start_time": "2024-02-20T03:01:02.666901633Z"
    }
   },
   "id": "73596173c1dccc13"
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file trained_hw2_model/config.json\n",
      "Model config OpenAIGPTConfig {\n",
      "  \"_name_or_path\": \"trained_hw2_model\",\n",
      "  \"afn\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"OpenAIGPTForSequenceClassification\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"None\",\n",
      "    \"1\": \"actor.gender\",\n",
      "    \"2\": \"gr.amount\",\n",
      "    \"3\": \"movie.country\",\n",
      "    \"4\": \"movie.directed_by\",\n",
      "    \"5\": \"movie.estimated_budget\",\n",
      "    \"6\": \"movie.genre\",\n",
      "    \"7\": \"movie.gross_revenue\",\n",
      "    \"8\": \"movie.initial_release_date\",\n",
      "    \"9\": \"movie.language\",\n",
      "    \"10\": \"movie.locations\",\n",
      "    \"11\": \"movie.music\",\n",
      "    \"12\": \"movie.produced_by\",\n",
      "    \"13\": \"movie.production_companies\",\n",
      "    \"14\": \"movie.rating\",\n",
      "    \"15\": \"movie.starring.actor\",\n",
      "    \"16\": \"movie.starring.character\",\n",
      "    \"17\": \"movie.subjects\",\n",
      "    \"18\": \"person.date_of_birth\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"None\": 0,\n",
      "    \"actor.gender\": 1,\n",
      "    \"gr.amount\": 2,\n",
      "    \"movie.country\": 3,\n",
      "    \"movie.directed_by\": 4,\n",
      "    \"movie.estimated_budget\": 5,\n",
      "    \"movie.genre\": 6,\n",
      "    \"movie.gross_revenue\": 7,\n",
      "    \"movie.initial_release_date\": 8,\n",
      "    \"movie.language\": 9,\n",
      "    \"movie.locations\": 10,\n",
      "    \"movie.music\": 11,\n",
      "    \"movie.produced_by\": 12,\n",
      "    \"movie.production_companies\": 13,\n",
      "    \"movie.rating\": 14,\n",
      "    \"movie.starring.actor\": 15,\n",
      "    \"movie.starring.character\": 16,\n",
      "    \"movie.subjects\": 17,\n",
      "    \"person.date_of_birth\": 18\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"openai-gpt\",\n",
      "  \"n_embd\": 32,\n",
      "  \"n_head\": 2,\n",
      "  \"n_layer\": 2,\n",
      "  \"n_positions\": 512,\n",
      "  \"pad_token_id\": 40478,\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.32.1\",\n",
      "  \"vocab_size\": 40480\n",
      "}\n",
      "\n",
      "loading configuration file trained_hw2_model/config.json\n",
      "Model config OpenAIGPTConfig {\n",
      "  \"_name_or_path\": \"trained_hw2_model\",\n",
      "  \"afn\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"OpenAIGPTForSequenceClassification\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"None\",\n",
      "    \"1\": \"actor.gender\",\n",
      "    \"2\": \"gr.amount\",\n",
      "    \"3\": \"movie.country\",\n",
      "    \"4\": \"movie.directed_by\",\n",
      "    \"5\": \"movie.estimated_budget\",\n",
      "    \"6\": \"movie.genre\",\n",
      "    \"7\": \"movie.gross_revenue\",\n",
      "    \"8\": \"movie.initial_release_date\",\n",
      "    \"9\": \"movie.language\",\n",
      "    \"10\": \"movie.locations\",\n",
      "    \"11\": \"movie.music\",\n",
      "    \"12\": \"movie.produced_by\",\n",
      "    \"13\": \"movie.production_companies\",\n",
      "    \"14\": \"movie.rating\",\n",
      "    \"15\": \"movie.starring.actor\",\n",
      "    \"16\": \"movie.starring.character\",\n",
      "    \"17\": \"movie.subjects\",\n",
      "    \"18\": \"person.date_of_birth\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"None\": 0,\n",
      "    \"actor.gender\": 1,\n",
      "    \"gr.amount\": 2,\n",
      "    \"movie.country\": 3,\n",
      "    \"movie.directed_by\": 4,\n",
      "    \"movie.estimated_budget\": 5,\n",
      "    \"movie.genre\": 6,\n",
      "    \"movie.gross_revenue\": 7,\n",
      "    \"movie.initial_release_date\": 8,\n",
      "    \"movie.language\": 9,\n",
      "    \"movie.locations\": 10,\n",
      "    \"movie.music\": 11,\n",
      "    \"movie.produced_by\": 12,\n",
      "    \"movie.production_companies\": 13,\n",
      "    \"movie.rating\": 14,\n",
      "    \"movie.starring.actor\": 15,\n",
      "    \"movie.starring.character\": 16,\n",
      "    \"movie.subjects\": 17,\n",
      "    \"person.date_of_birth\": 18\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"openai-gpt\",\n",
      "  \"n_embd\": 32,\n",
      "  \"n_head\": 2,\n",
      "  \"n_layer\": 2,\n",
      "  \"n_positions\": 512,\n",
      "  \"pad_token_id\": 40478,\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.32.1\",\n",
      "  \"vocab_size\": 40480\n",
      "}\n",
      "\n",
      "loading weights file trained_hw2_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing OpenAIGPTForSequenceClassification.\n",
      "\n",
      "All the weights of OpenAIGPTForSequenceClassification were initialized from the model checkpoint at trained_hw2_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use OpenAIGPTForSequenceClassification for predictions without further training.\n",
      "loading file vocab.json\n",
      "loading file merges.txt\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                       precision    recall  f1-score   support\n",
      "\n",
      "                                                 None       0.82      0.54      0.65       100\n",
      "                                        movie.country       0.53      0.64      0.58        25\n",
      "                         movie.country movie.language       0.00      0.00      0.00         0\n",
      "movie.country movie.language movie.genre movie.rating       0.00      0.00      0.00         0\n",
      "                                    movie.directed_by       0.83      0.60      0.70        96\n",
      "         movie.directed_by movie.initial_release_date       0.00      0.00      0.00         0\n",
      "                               movie.estimated_budget       0.27      1.00      0.43         3\n",
      "                                          movie.genre       0.19      0.50      0.27         6\n",
      "                           movie.genre movie.subjects       0.00      0.00      0.00         0\n",
      "                                  movie.gross_revenue       0.00      0.00      0.00         0\n",
      "                        movie.gross_revenue gr.amount       0.00      0.00      0.00         0\n",
      "                           movie.initial_release_date       0.58      0.83      0.68        18\n",
      "                                       movie.language       0.95      0.39      0.55        49\n",
      "                                          movie.music       0.00      0.00      0.00         0\n",
      "                                    movie.produced_by       0.55      0.62      0.58        37\n",
      "                           movie.production_companies       0.06      1.00      0.11         1\n",
      "movie.production_companies movie.initial_release_date       0.00      0.00      0.00         0\n",
      "                                         movie.rating       0.77      0.70      0.73        53\n",
      "                             movie.rating movie.genre       0.00      0.00      0.00         0\n",
      "                                 movie.starring.actor       0.52      0.61      0.56        49\n",
      "                    movie.starring.actor actor.gender       0.00      0.00      0.00         0\n",
      "      movie.starring.actor movie.initial_release_date       0.00      0.00      0.00         0\n",
      "        movie.starring.actor movie.starring.character       0.00      0.00      0.00         0\n",
      "                                       movie.subjects       0.60      0.43      0.50        14\n",
      "                                 person.date_of_birth       0.00      0.00      0.00         0\n",
      "\n",
      "                                             accuracy                           0.59       451\n",
      "                                            macro avg       0.27      0.31      0.25       451\n",
      "                                         weighted avg       0.73      0.59      0.63       451\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "infer = pipeline(task=\"text-classification\", model=model_dir)\n",
    "val_preds = [infer(utt)[0][\"label\"] for utt in intent_val[\"utterances\"]]\n",
    "val_true =  [relation for relation in intent_val[\"Core Relations\"]]\n",
    "val_true =  ['None' if relation is None else relation for relation in val_true]\n",
    "print(classification_report(val_preds, val_true, zero_division=0.0))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T03:01:08.414347532Z",
     "start_time": "2024-02-20T03:01:06.720707391Z"
    }
   },
   "id": "ea213c87f5c692ec"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "50472f445de35b0e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
